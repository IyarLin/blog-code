<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ab_testing on Just be-cause</title>
    <link>https://iyarlin.github.io/tags/ab_testing/</link>
    <description>Recent content in ab_testing on Just be-cause</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://iyarlin.github.io/tags/ab_testing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Better A/B testing with survival analysis</title>
      <link>https://iyarlin.github.io/2024/07/10/better_ab_testing_with_survival/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>https://iyarlin.github.io/2024/07/10/better_ab_testing_with_survival/</guid>
      <description>Pic by author - using DALL-E 3 When running experiments don’t forget to bring your survival kit I’ve already made the case in several blog posts (part 1, part 2, part 3) that using survival analysis can improve churn prediction.
In this blog post I’ll show another use case where survival analysis can improve on common practices: A/B testing!
The problems with common A/B testing practices Usually when running an A/B test analysts assign users randomly to variants over time and measure conversion rate as the ratio between the number of conversions and the number of users in each variant.</description>
    </item>
    
  </channel>
</rss>
